<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Load Dataset – Oxford_102_Flower_Tiny_DDPM</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Oxford_102_Flower_Tiny_DDPM</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Load Dataset</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="cell-2" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722955931,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:9628,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> make_grid, save_image</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, ConcatDataset</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-3" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="19408190-7550-4b27-97df-5068f669f8cc" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 전처리 미리 정의</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>IMG_RES <span class="op">=</span> (<span class="dv">64</span>, <span class="dv">64</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    transforms.Resize(IMG_RES),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(), <span class="co"># 1) [0.0, 1.0] 실수 범위로 압축, 2) (H, W, C) -&gt; (C, H, W)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)) <span class="co"># 각각의 RGB 채널 평균 0.5, 표준편차 0.5로 Norm</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Load train/validation/test datasets</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>train_set <span class="op">=</span> torchvision.datasets.Flowers102(root<span class="op">=</span><span class="st">'./data'</span>, split<span class="op">=</span><span class="st">'train'</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>val_set <span class="op">=</span> torchvision.datasets.Flowers102(root<span class="op">=</span><span class="st">'./data'</span>, split<span class="op">=</span><span class="st">'val'</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>test_set <span class="op">=</span> torchvision.datasets.Flowers102(root<span class="op">=</span><span class="st">'./data'</span>, split<span class="op">=</span><span class="st">'test'</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. 데이터셋 3종류 하나로 합치기(validation, test 불필요)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> ConcatDataset([train_set, val_set, test_set])</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. 필요없는 변수 삭제 -&gt; 메모리 절약</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> train_set, val_set, test_set</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. dataloader</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    dataset,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>BATCH_SIZE, <span class="co"># 64개씩 batch 만들기</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>, <span class="co"># 섞기</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    drop_last<span class="op">=</span><span class="va">True</span>, <span class="co"># 자투리 버리기</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    pin_memory<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 345M/345M [00:09&lt;00:00, 37.0MB/s]
100%|██████████| 502/502 [00:00&lt;00:00, 2.14MB/s]
100%|██████████| 15.0k/15.0k [00:00&lt;00:00, 40.6MB/s]</code></pre>
</div>
</div>
<div id="cell-4" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722975609,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:562,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-outputid="c7326131-6596-4907-cccb-a49002e39ec5" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># shape 확인</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>iterForShapeCheck <span class="op">=</span> <span class="bu">iter</span>(dataloader)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>oneBatchTensorForShapeCheck <span class="op">=</span> <span class="bu">next</span>(iterForShapeCheck)[<span class="dv">0</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape of One Batch: </span><span class="sc">{</span>oneBatchTensorForShapeCheck<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of One Batch: torch.Size([64, 3, 64, 64])</code></pre>
</div>
</div>
<div id="cell-5" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722976438,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:828,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-outputid="8a3e8005-3821-4f98-8f32-8521a0889bf8" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 10개만 시각화해서 확인</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">## 1) batch 하나 준비</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>dataIterator <span class="op">=</span> <span class="bu">iter</span>(dataloader) <span class="co"># dataloader은 iterable 하지만 iterator는 아님 -&gt; iterator로 만들어주기</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(dataIterator) <span class="co"># images, labels에 batch 하나가 담김</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">## 2) 도화지 정의</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">10</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span>)) <span class="co"># fig: 전체 도화지, axes: 각각의 칸(numpy array)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.1</span>) <span class="co"># 이미지 사이 간격</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">## 3) 그림 그리기</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> images[i]</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> (img <span class="op">*</span> <span class="fl">0.5</span>) <span class="op">+</span> <span class="fl">0.5</span> <span class="co"># Normalize 했던거 원래대로 복구</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> img.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>) <span class="co"># (C, H, W) -&gt; (H, W, C)</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  axes[i].imshow(img.cpu().numpy()) <span class="co"># numpy(): Tensor -&gt; Numpy Array</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  axes[i].axis(<span class="st">'off'</span>) <span class="co"># 눈금제거</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"10 Images from Oxford 102 Flowers"</span>, y<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="diffusion-schedule-forward-process" class="level2">
<h2 class="anchored" data-anchor-id="diffusion-schedule-forward-process">Diffusion Schedule (Forward Process)</h2>
<div id="cell-7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722976443,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:3,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3가지 diffusion schedules - Linear/Cosine/Offset Cosine</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DiffusionSchedules:</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, T<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.T <span class="op">=</span> T</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.times <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">1</span>, T) <span class="co"># [0.000, 0.001, 0.002, ... 0.999, 1.000]</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">## 1) Linear Diffusion Schedules</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">### t 지나면서 beta가 linear 하게 커짐</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> linear_diffusion_schedule(<span class="va">self</span>):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">## beta 범위 설정</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    min_beta <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    max_beta <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># betas, alphas, alpha_bars</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    betas <span class="op">=</span> min_beta <span class="op">+</span> <span class="va">self</span>.times <span class="op">*</span> (max_beta <span class="op">-</span> min_beta)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> betas</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    alpha_bars <span class="op">=</span> torch.cumprod(alphas, dim<span class="op">=</span><span class="dv">0</span>) <span class="co"># coumprod: 누적 곱셈 [2, 3, 5] -&gt; [2, 6, 30]</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># noise, blur rates(tensor)</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    noise_rates <span class="op">=</span> torch.sqrt(<span class="dv">1</span> <span class="op">-</span> alpha_bars)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    blur_rates <span class="op">=</span> torch.sqrt(alpha_bars)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> blur_rates, noise_rates <span class="co"># 앞에 곱하는걸 앞에 썼음.</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">## 2) Cosine Diffusion Schedules</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>  <span class="co">### sin^2 + cos^2 = 1 이용한 schedule</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> cosine_diffusion_schedule(<span class="va">self</span>):</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    blur_rates <span class="op">=</span> torch.cos(<span class="va">self</span>.times <span class="op">*</span> math.pi <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    noise_rates <span class="op">=</span> torch.sin(<span class="va">self</span>.times <span class="op">*</span> math.pi <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> blur_rates, noise_rates</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">## 3) Offset Cosine Schedules</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>  <span class="co">### 너무 어둡거나 밝은 이미지 생성 방지</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> offset_diffusion_schedule(<span class="va">self</span>):</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    min_blur_rate <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    max_blur_rate <span class="op">=</span> <span class="fl">0.999</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    max_blur <span class="op">=</span> torch.tensor(max_blur_rate).clamp(<span class="op">-</span><span class="dv">1</span><span class="op">+</span><span class="fl">1e-6</span>, <span class="dv">1</span><span class="op">-</span><span class="fl">1e-6</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    min_blur <span class="op">=</span> torch.tensor(min_blur_rate).clamp(<span class="op">-</span><span class="dv">1</span><span class="op">+</span><span class="fl">1e-6</span>, <span class="dv">1</span><span class="op">-</span><span class="fl">1e-6</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># min, max의 cos 각도</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    start_angle <span class="op">=</span> torch.acos(max_blur)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    end_angle   <span class="op">=</span> torch.acos(min_blur)</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 각도를 linear하게 세팅해서 sin, cos 사용</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>    diffusion_angles <span class="op">=</span> start_angle <span class="op">+</span> <span class="va">self</span>.times <span class="op">*</span> (end_angle <span class="op">-</span> start_angle)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>    blur_rates <span class="op">=</span> torch.cos(diffusion_angles)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    noise_rates <span class="op">=</span> torch.sin(diffusion_angles)</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> blur_rates, noise_rates</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="schedules-visualizations" class="level3">
<h3 class="anchored" data-anchor-id="schedules-visualizations">Schedules Visualizations</h3>
<div id="cell-9" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722976446,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:1,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Schedule별 blur_rates, noise_rates 시각화</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>schedules <span class="op">=</span> DiffusionSchedules(T<span class="op">=</span><span class="dv">1000</span>) <span class="co"># Schdule들 모아놓은 class 호출</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>linear_blurs, linear_noises <span class="op">=</span> schedules.linear_diffusion_schedule()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>cosine_blurs, cosine_noises <span class="op">=</span> schedules.cosine_diffusion_schedule()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>offset_blurs, offset_noises <span class="op">=</span> schedules.offset_diffusion_schedule()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>diffusion_times <span class="op">=</span> schedules.times</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722976651,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:204,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-outputid="445215a6-96ef-4837-fe50-cc117627e788" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#1. blurs: alpha_t bar</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>plt.plot(diffusion_times, linear_blurs<span class="op">**</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">"#990099"</span>, label<span class="op">=</span><span class="st">"linear Schedule"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.plot(diffusion_times, cosine_blurs<span class="op">**</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">"#3b3eac"</span>, label<span class="op">=</span><span class="st">"cosine Schedule"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>plt.plot(diffusion_times, offset_blurs<span class="op">**</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">"#329262"</span>, label<span class="op">=</span><span class="st">"Offset Cosine Schedule"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"t / T"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"</span><span class="dv">$\b</span><span class="vs">ar{</span><span class="ch">\a</span><span class="vs">lpha_t}</span><span class="dv">$</span><span class="vs"> </span><span class="kw">(</span><span class="vs">Blur</span><span class="kw">)</span><span class="vs">"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722976777,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:125,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-outputid="53f23fa5-261f-4fc6-9523-92ea60320f11" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#2. noises: 1 - alpha_t bar</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plt.plot(diffusion_times, linear_noises<span class="op">**</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"linear Schedule"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>plt.plot(diffusion_times, cosine_noises<span class="op">**</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"cosine Schedule"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>plt.plot(diffusion_times, offset_noises<span class="op">**</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"Offset Cosine Schedule"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"t / T"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"</span><span class="dv">$</span><span class="vs">1-</span><span class="dv">\b</span><span class="vs">ar{</span><span class="ch">\a</span><span class="vs">lpha_t}</span><span class="dv">$</span><span class="vs"> </span><span class="kw">(</span><span class="vs">Noise</span><span class="kw">)</span><span class="vs">"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="build-parts-for-model" class="level2">
<h2 class="anchored" data-anchor-id="build-parts-for-model">Build Parts for Model</h2>
<section id="sinusoidal-embedding" class="level3">
<h3 class="anchored" data-anchor-id="sinusoidal-embedding">Sinusoidal Embedding</h3>
<div id="cell-14" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722976779,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:1,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SinusoidalTimeEmbedding(nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># class가 호출되면 -&gt; __init__실행 -&gt; nn.Module(pytorch)의 __init__ 실행</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()  <span class="co"># super(): 상속받은 부모 클래스인 nn.Module</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> dim <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> dim <span class="op">&gt;=</span> <span class="dv">4</span>, <span class="st">"time embedding dim must be even and &gt;= 4"</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.dim <span class="op">=</span> dim  <span class="co"># self: SinusoidalTimeEmbedding로 만든 instance</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, time):</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># input: time - (Batch_Size, ) shape의 1D tensor</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># output: embeddings - (Batch_Size, dim) shpae의 2D tensor</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> time.device <span class="co"># time이 있을 공간(CPU or GPU)이 나중에 연산을 할 기준 공간</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># frequency: 1 / 10000^(2i / dim) -&gt; 1 / 10000^(i / half_dim - 1) [0부터 시작하니까]</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># log 씌워서 계산 (컴퓨터가 계산하기 더 좋다고 함)</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># - {i / (half_dim - 1)} * log(10000) = -i * {log(10000) / half_dim - 1}</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1. half_dim 계산</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    half_dim <span class="op">=</span> <span class="va">self</span>.dim <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 2. log(10000) / half_dim - 1</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    pre_frequency <span class="op">=</span> math.log(<span class="dv">10000</span>) <span class="op">/</span> (half_dim <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3. i 만들기</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> torch.arange(half_dim, device<span class="op">=</span>device)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">##4. frequency 완성</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    frequency <span class="op">=</span> torch.exp(<span class="op">-</span>i <span class="op">*</span> pre_frequency)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># time(Batch_size, )와 frequency(half_dim, ) 텐서 변형해서 행렬곱 -&gt; half_embeddings(Batch_size, half_dim)</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    half_embeddings <span class="op">=</span> time[:, <span class="va">None</span>] <span class="op">*</span> frequency[<span class="va">None</span>, :]</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># half_embeddings에 sin, cos 적용해서 수평으로 붙이기 -&gt; embeddings(Batch_size, dim) 완성</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> torch.cat((half_embeddings.sin(), half_embeddings.cos()), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embeddings</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="visualization" class="level4">
<h4 class="anchored" data-anchor-id="visualization">Visualization</h4>
<div id="cell-16" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722977305,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:525,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-outputid="0d6c3433-83b4-4d4a-c5aa-8b3794af0b3a" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># instance</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>embedding_dim <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>time_embedder <span class="op">=</span> SinusoidalTimeEmbedding(embedding_dim) <span class="co"># sinusoidal 인스턴스 생성(32차원으로)</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>times_sample <span class="op">=</span> torch.arange(<span class="dv">1000</span>) <span class="co"># t = 0 ~ 999</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> time_embedder(times_sample) <span class="co"># time_embedder.forward() 안 해도 forward 호출해준다 (pytorch에 call함수로 잘 설계돼있다)</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>embedding_matrix <span class="op">=</span> embeddings.cpu().numpy().T <span class="co"># embedding을 transpose -&gt; x축: t, y축: dim</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># aspect='auto': 픽셀 하나 정사각형 고집 부리지말고 figsize에 맞춰서 꽉 채워라</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># origin='lower': 수학 그래프 그리듯이 원점을 가장 아래에 둬라</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>plt.imshow(embedding_matrix, aspect<span class="op">=</span><span class="st">'auto'</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, origin<span class="op">=</span><span class="st">'lower'</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Sinusoidal Time Embeddings with 1000 Timesteps"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Time Step (t)"</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Dimension"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.colorbar(label<span class="op">=</span><span class="st">"Value"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="residual-block" class="level3">
<h3 class="anchored" data-anchor-id="residual-block">Residual Block</h3>
<section id="normalization-정리" class="level5">
<h5 class="anchored" data-anchor-id="normalization-정리">Normalization 정리</h5>
<p>(N=64, C=64, H=64, W=64) 기준 - <strong>Batch Norm</strong>: Batch 1 안에서 Channel 1을 끌어모아서 모든 픽셀에 대해 평균, 표준편차 구함 -&gt; Batch 1 안에서 C(채널 개수)개의 평균과 표준편차 나옴 -&gt; N 고정, C고정 - <strong>Layer Norm</strong>: Img 1에서 모든 픽셀에 대해 평균, 표준편차 구함 -&gt; Batch 하나 당 Batch_Size개의 평균과 표준편차 나옴 -&gt; C, H, W 고정 - <strong>Group Norm</strong>: Img 1, Channel 1, 2 에서 모든 픽셀에 대해 평균, 표준편차 구함 -&gt; 보통 사진 하나 당 그룹을 32개로 고정 -&gt; Batch 하나 당 32 * Batch_Size 개의 평균과 표준편차 나옴 -&gt; N, H, W 고정, C 그룹화 고정</p>
<div id="cell-19" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722977309,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:2,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResidualBlock(nn.Module):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_channels, output_channels, time_emb_dim, groups<span class="op">=</span><span class="dv">8</span>): <span class="co"># groups: GroupNorm 할 때 그룹개수(32개가 국룰이지만 채널 개수 충분하지 않아서 8로)</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part 1</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 3x3 convolution layer에 통과시킨다. padding 1로 줘야 projection 의 사이즈가 원래 이미지 사이즈랑 같아짐</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">## poj_size = img_size - conv_size + 1 에서 conv_size = 3 이므로 poj_size = img_size - 2 -&gt; img_size에 2 더해줘야 같아짐</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.proj1 <span class="op">=</span> nn.Conv2d(input_channels, output_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">## GroupNorm</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.norm1 <span class="op">=</span> nn.GroupNorm(groups, output_channels)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Activation function: SiLU = x * sigma(x), where sigma(x) = sigmoid</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.act1 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># time embedding part</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.time_embedding <span class="op">=</span> nn.Sequential(</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        nn.SiLU(), <span class="co"># time embedding을 SiLU에 통과시켜서 비선형성 부여</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        nn.Linear(time_emb_dim, output_channels) <span class="co"># FFN 통과시켜서 output_channel이랑 time_emb_dim 똑같이 만들어줌</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part 2</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.proj2 <span class="op">=</span> nn.Conv2d(output_channels, output_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.norm2 <span class="op">=</span> nn.GroupNorm(groups, output_channels)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.act2 <span class="op">=</span> nn.SiLU()</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># residual connection part</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">## channel 다르면 1x1 convolution으로 맞춰준다</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> input_channels <span class="op">!=</span> output_channels:</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.connection <span class="op">=</span> nn.Conv2d(input_channels, output_channels, kernel_size<span class="op">=</span><span class="dv">1</span>) <span class="co"># (input_channels, 1, 1)인 kernel을 output_channels개 준비해서 convolution</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.connection <span class="op">=</span> nn.Identity() <span class="co"># 그냥 통과(y = x)</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x(img): (Batch_Size, input_channels, H, W)</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># t: (Batch_Size, time_emb_dim)</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    h_for_connection <span class="op">=</span> x <span class="co"># Residual Connection 위해서 저장</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part 1</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.proj1(x)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.norm1(h)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.act1(h)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># time embedding adding part</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    time_emb <span class="op">=</span> <span class="va">self</span>.time_embedding(t) <span class="co"># time embedding 변환 -&gt; (Batch_Size, output_channels)</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> h <span class="op">+</span> time_emb[:, :, <span class="va">None</span>, <span class="va">None</span>] <span class="co"># time_emb: (Batch_Size, output_channels) -&gt; (Batch_Size, output_channels, 1, 1) (H, W)가 (1, 1)이 아니어도 같은 값 다 더해짐</span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part 2</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.proj2(h)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.norm2(h)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.act2(h)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># residual connection part(return)</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> h <span class="op">+</span> <span class="va">self</span>.connection(h_for_connection)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="attention-block" class="level3">
<h3 class="anchored" data-anchor-id="attention-block">Attention Block</h3>
<div id="cell-21" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722977311,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:1,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(nn.Module):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, groups<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1. Group Norm</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.norm <span class="op">=</span> nn.GroupNorm(groups, channels)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2. Q, K, V 만들 1x1 Convolution Layer</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.qkv_layer <span class="op">=</span> nn.Conv2d(channels, channels <span class="op">*</span> <span class="dv">3</span>, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3. 마무리 projection할 Convolution Layer</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.proj <span class="op">=</span> nn.Conv2d(channels, channels, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    B, C, H, W <span class="op">=</span> x.shape <span class="co"># shape 정보 필요</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> x <span class="co"># for skip-connection</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Norm, QKV</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    qkv <span class="op">=</span> <span class="va">self</span>.qkv_layer(<span class="va">self</span>.norm(h))</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (B, 3C, H, W) -&gt; (B, 3C, H*W) -&gt; (B, H*W, 3C)</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    qkv <span class="op">=</span> qkv.reshape(B, C <span class="op">*</span> <span class="dv">3</span>, <span class="op">-</span><span class="dv">1</span>).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Query, Key, Value 분해</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    q, k, v <span class="op">=</span> qkv.chunk(<span class="dv">3</span>, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Attention score</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">## softmax(Q * K^T/sqrt(d))</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    scale <span class="op">=</span> <span class="bu">int</span>(C) <span class="op">**</span> (<span class="op">-</span><span class="fl">0.5</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    attn <span class="op">=</span> torch.bmm(q, k.transpose(<span class="dv">1</span>, <span class="dv">2</span>)) <span class="op">*</span> scale <span class="co"># bmm = batch matrix multiplication</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    attn <span class="op">=</span> torch.nn.functional.softmax(attn, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">## softmax(Q * K^T/sqrt(d)) * v</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> torch.bmm(attn, v)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 원래 shape으로 복구</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (B, H*W, C) -&gt; (B, C, H*W) -&gt; (B, C, H, W)</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> h.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>).reshape(B, C, H, W)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># final projection, add(skip-connection)</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="va">self</span>.proj(h)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="down-block" class="level3">
<h3 class="anchored" data-anchor-id="down-block">Down Block</h3>
<div id="cell-23" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722977313,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:1,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DownBlock(nn.Module):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_channels, output_channels, time_emb_dim, groups<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part 1: residual block 2개 쌓기</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.res_block1 <span class="op">=</span> ResidualBlock(input_channels, output_channels, time_emb_dim, groups)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.res_block2 <span class="op">=</span> ResidualBlock(output_channels, output_channels, time_emb_dim, groups)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part 2: Downsampling</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.downsample <span class="op">=</span> nn.Conv2d(output_channels, output_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>) <span class="co"># 두 칸씩 이동해서 픽셀 수 절반으로 줄임</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x: B(Batch_size, input_channels, H, W)</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># residual block 두 번 통과</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.res_block1(x, t)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.res_block2(x, t)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># downsampling</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> x</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.downsample(x) <span class="co"># (Batch_Size, output_channels, H/2, W/2)</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="up-block" class="level3">
<h3 class="anchored" data-anchor-id="up-block">Up Block</h3>
<div id="cell-25" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722977318,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:4,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UpBlock(nn.Module):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_channels, output_channels, time_emb_dim, groups<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part1: upsampling</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Transposed Convolution: 픽셀 한 칸을 여러 칸으로 흩뿌리기(Convoludtion의 역연산) -&gt; 2배로 커짐</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.upsample <span class="op">=</span> nn.ConvTranspose2d(input_channels, output_channels, kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>) <span class="co"># 2*2 영역에 뿌리기, 새 도화지에서 2칸씩 이동</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># part2: residual block 2개 쌓기</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.res_block1 <span class="op">=</span> ResidualBlock(output_channels <span class="op">*</span> <span class="dv">2</span>, output_channels, time_emb_dim, groups) <span class="co"># Residual connection 한 것과 올라온 x 합칠 것</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.res_block2 <span class="op">=</span> ResidualBlock(output_channels, output_channels, time_emb_dim, groups)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x, residual, t):</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x: (Batch_Size, input_channels, H, W) -&gt; down block 거쳐온 이미지</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># residual: (Batch_Size, output_channels, H*2, W*2) -&gt; Down Block에서 저장해둔 것</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Upsampling(H, W -&gt; 2H, 2W)</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.upsample(x)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Concatenation</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## dim=1 방향: Channel 방향</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">## (B, C, H, W) -&gt; (B, 2C, H, W)</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.cat([x, residual], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ResBlock 통과시키기</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.res_block1(x, t)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.res_block2(x, t)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="u-net" class="level3">
<h3 class="anchored" data-anchor-id="u-net">U-Net</h3>
<div id="cell-27" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765722977321,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:1,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNet(nn.Module):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channel_in <span class="op">=</span> <span class="dv">3</span>, channel_out <span class="op">=</span> <span class="dv">3</span>, time_dim <span class="op">=</span> <span class="dv">32</span>):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1. Time Embedding</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.time_dim <span class="op">=</span> time_dim</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.time_mlp <span class="op">=</span> nn.Sequential(</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        SinusoidalTimeEmbedding(time_dim), <span class="co"># time embedding 생성</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        nn.Linear(time_dim, time_dim), <span class="co"># FFN</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        nn.SiLU() <span class="co"># activation function -&gt; 선형성 깨뜨리기</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2. Initial Image Transform(3 Channels -&gt; 64 Channels)</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.conv_init <span class="op">=</span> nn.Conv2d(channel_in, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3. Down</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.down1 <span class="op">=</span> DownBlock(<span class="dv">64</span>, <span class="dv">128</span>, time_dim) <span class="co"># 64 -&gt; 128</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.down2 <span class="op">=</span> DownBlock(<span class="dv">128</span>, <span class="dv">256</span>, time_dim) <span class="co"># 128 -&gt; 256</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4. Bottom</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bottom1 <span class="op">=</span> ResidualBlock(<span class="dv">256</span>, <span class="dv">256</span>, time_dim)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.attn_bottom <span class="op">=</span> AttentionBlock(<span class="dv">256</span>) <span class="co"># Attention Block</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bottom2 <span class="op">=</span> ResidualBlock(<span class="dv">256</span>, <span class="dv">256</span>, time_dim)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">#5. Up</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.up1 <span class="op">=</span> UpBlock(<span class="dv">256</span>, <span class="dv">256</span>, time_dim)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.up2 <span class="op">=</span> UpBlock(<span class="dv">256</span>, <span class="dv">128</span>, time_dim)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#6. Output</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.conv_out <span class="op">=</span> nn.Conv2d(<span class="dv">128</span>, channel_out, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> <span class="va">self</span>.time_mlp(t) <span class="co"># time embedding</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.conv_init(x) <span class="co"># initial transform</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>    x, h1 <span class="op">=</span> <span class="va">self</span>.down1(x, t) <span class="co"># down, save input</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    x, h2 <span class="op">=</span> <span class="va">self</span>.down2(x, t)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.bottom1(x, t) <span class="co"># bottom</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.attn_bottom(x)</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.bottom2(x, t)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.up1(x, h2, t) <span class="co"># up(skip connection)</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.up2(x, h1, t)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.conv_out(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="build-diffusion-model" class="level2">
<h2 class="anchored" data-anchor-id="build-diffusion-model">Build Diffusion Model</h2>
<div id="cell-29" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1765723957358,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:20,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DiffusionModel(nn.Module):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, network):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.network <span class="op">=</span> network <span class="co"># U-Net</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.T <span class="op">=</span> <span class="dv">1000</span> <span class="co"># number of timestep</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    schedules <span class="op">=</span> DiffusionSchedules(T<span class="op">=</span><span class="va">self</span>.T) <span class="co"># Scheduler instance</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.blur_rates, <span class="va">self</span>.noise_rates <span class="op">=</span> schedules.linear_diffusion_schedule() <span class="co"># scheduler: linear로 선택</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Buffer로 등록(GPU로 이동)</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.register_buffer(<span class="st">"blur_rates_buffer"</span>, <span class="va">self</span>.blur_rates)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.register_buffer(<span class="st">"noise_rates_buffer"</span>, <span class="va">self</span>.noise_rates)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x_0):</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># x_0: 원본 이미지</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> x_0.shape[<span class="dv">0</span>]</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> x_0.device <span class="co"># 마찬가지로 기준 연산공간 지정</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1. random t sampling: (batch_size, )만큼</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="va">self</span>.T, (batch_size, ), device<span class="op">=</span>device)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2. 뽑은 t에 대해 blur_rate, noise_rate 준비 -&gt; (batch_size, 1, 1, 1) shape으로</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    blur_rate <span class="op">=</span> <span class="va">self</span>.blur_rates_buffer[t].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    noise_rate <span class="op">=</span> <span class="va">self</span>.noise_rates_buffer[t].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3. random noise -&gt; label</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn_like(x_0) <span class="co"># x_0랑 같은 모양으로 N(0, 1)에서 sampling</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4. Forward Process</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    img_noisy <span class="op">=</span> blur_rate <span class="op">*</span> x_0 <span class="op">+</span> noise_rate <span class="op">*</span> noise</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">#5. 망가진 이미지, t 주고 U-Net이 Noise 예측</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    pred_noise <span class="op">=</span> <span class="va">self</span>.network(img_noisy, t)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#6. Loss</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> nn.functional.mse_loss(pred_noise, noise)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>  <span class="at">@torch.no_grad</span>()</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> sample(<span class="va">self</span>, image_size, batch_size<span class="op">=</span><span class="dv">8</span>, channels<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.parameters()).device</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. 완전한 noise에서 시작</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> torch.randn((batch_size, channels, image_size, image_size), device<span class="op">=</span>device)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. T-1 -&gt; 0으로 denoising</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.T <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        t_batch <span class="op">=</span> torch.full((batch_size,), t, device<span class="op">=</span>device, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Noise prediction</span></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        pred_noise <span class="op">=</span> <span class="va">self</span>.network(img, t_batch)</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Current timestep의 blur/noise rates</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>        current_blur <span class="op">=</span> <span class="va">self</span>.blur_rates_buffer[t]</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>        current_noise <span class="op">=</span> <span class="va">self</span>.noise_rates_buffer[t]</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Previous timestep의 blur rate</span></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>            previous_blur <span class="op">=</span> <span class="va">self</span>.blur_rates_buffer[t <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>            previous_blur <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>, device<span class="op">=</span>device)</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Alpha_bar 계산</span></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>        alpha_bar_t <span class="op">=</span> current_blur <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        alpha_bar_prev <span class="op">=</span> previous_blur <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Alpha_t 계산</span></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> alpha_bar_t <span class="op">/</span> torch.clamp(alpha_bar_prev, <span class="bu">min</span><span class="op">=</span>epsilon)</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> alpha_t.clamp(epsilon, <span class="fl">1.0</span>)</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>, device<span class="op">=</span>device)</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Beta_t 계산</span></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>        beta_t <span class="op">=</span> (<span class="fl">1.0</span> <span class="op">-</span> alpha_t).clamp(<span class="bu">min</span><span class="op">=</span><span class="fl">0.0</span>, <span class="bu">max</span><span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mean 계산</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>        sqrt_one_minus_alpha_bar_t <span class="op">=</span> torch.sqrt(torch.clamp(<span class="fl">1.0</span> <span class="op">-</span> alpha_bar_t, <span class="bu">min</span><span class="op">=</span>epsilon))</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>        coef <span class="op">=</span> beta_t <span class="op">/</span> sqrt_one_minus_alpha_bar_t</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>        sqrt_alpha_t <span class="op">=</span> torch.sqrt(torch.clamp(alpha_t, <span class="bu">min</span><span class="op">=</span>epsilon))</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>        mean <span class="op">=</span> (<span class="fl">1.0</span> <span class="op">/</span> sqrt_alpha_t) <span class="op">*</span> (img <span class="op">-</span> coef <span class="op">*</span> pred_noise)</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Variance와 noise 추가</span></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>            numerator <span class="op">=</span> beta_t <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">-</span> alpha_bar_prev)</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>            denominator <span class="op">=</span> torch.clamp(<span class="fl">1.0</span> <span class="op">-</span> alpha_bar_t, <span class="bu">min</span><span class="op">=</span>epsilon)</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>            posterior_var <span class="op">=</span> numerator <span class="op">/</span> denominator</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>            posterior_var <span class="op">=</span> posterior_var.clamp(<span class="bu">min</span><span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>            sigma_t <span class="op">=</span> torch.sqrt(posterior_var)</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>            z <span class="op">=</span> torch.randn_like(img)</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> mean <span class="op">+</span> sigma_t <span class="op">*</span> z</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> mean</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.clamp(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>)</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> (img <span class="op">+</span> <span class="fl">1.0</span>) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> img</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train</h2>
<div id="cell-31" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;executionInfo&quot;,&quot;value&quot;:{&quot;status&quot;:&quot;error&quot;,&quot;timestamp&quot;:1765724362976,&quot;user_tz&quot;:-540,&quot;elapsed&quot;:403330,&quot;user&quot;:{&quot;displayName&quot;:&quot;이형석&quot;,&quot;userId&quot;:&quot;10765881790672155751&quot;}}}" data-outputid="99283aa5-8938-4129-ce6d-c903f2520d0a" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#1. Model, Optimizer</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>unet <span class="op">=</span> UNet(channel_in<span class="op">=</span><span class="dv">3</span>, channel_out<span class="op">=</span><span class="dv">3</span>, time_dim<span class="op">=</span><span class="dv">32</span>).to(device)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DiffusionModel(network<span class="op">=</span>unet).to(device)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">#2. Folders for saving</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>OUT_DIR <span class="op">=</span> <span class="st">"./output"</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>CKPT_DIR <span class="op">=</span> <span class="st">"./checkpoint"</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>os.makedirs(OUT_DIR, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>os.makedirs(CKPT_DIR, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">#3. Learning Loop</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>NUM_SAMPLE <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>SAMPLE_EVERY <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>SAVE_CKPT_EVERY <span class="op">=</span> <span class="dv">50</span>  <span class="co"># 50 epoch마다 체크포인트 저장</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss 기록용</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>loss_history <span class="op">=</span> []</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Starting training for </span><span class="sc">{</span>EPOCHS<span class="sc">}</span><span class="ss"> epochs..."</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total batches per epoch: </span><span class="sc">{</span><span class="bu">len</span>(dataloader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(EPOCHS):</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, _ <span class="kw">in</span> dataloader:</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> images.to(device)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> model(images)</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>        num_batches <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>    avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> <span class="bu">max</span>(<span class="dv">1</span>, num_batches)</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>    loss_history.append(avg_loss)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Progress print</span></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:3d}</span><span class="ss">/</span><span class="sc">{</span>EPOCHS<span class="sc">}</span><span class="ss">] avg_loss = </span><span class="sc">{</span>avg_loss<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 샘플 이미지 생성 (SAMPLE_EVERY마다)</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> SAMPLE_EVERY <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> epoch <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>            torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>                torch.cuda.manual_seed_all(<span class="dv">42</span>)</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>            samples <span class="op">=</span> model.sample(image_size<span class="op">=</span>IMG_SIZE, batch_size<span class="op">=</span>NUM_SAMPLE, channels<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>            grid <span class="op">=</span> make_grid(samples.cpu(), nrow<span class="op">=</span><span class="dv">10</span>, padding<span class="op">=</span><span class="dv">2</span>, pad_value<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>            grid <span class="op">=</span> grid.clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>            save_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>OUT_DIR<span class="sc">}</span><span class="ss">/generated_img_</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:03d}</span><span class="ss">.png"</span></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>            save_image(grid, save_path)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>            plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>            plt.imshow(grid.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).numpy())</span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>            plt.axis(<span class="st">"off"</span>)</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="ss">f"Generated Images at Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>            plt.tight_layout()</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>            plt.show()</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"✓ Saved image: </span><span class="sc">{</span>save_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 체크포인트 저장 (SAVE_CKPT_EVERY마다)</span></span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> SAVE_CKPT_EVERY <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>        checkpoint <span class="op">=</span> {</span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">'epoch'</span>: epoch <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>            <span class="st">'model_state_dict'</span>: model.state_dict(),</span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>            <span class="st">'optimizer_state_dict'</span>: optimizer.state_dict(),</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>            <span class="st">'loss'</span>: avg_loss,</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>            <span class="st">'loss_history'</span>: loss_history,</span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>        ckpt_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>CKPT_DIR<span class="sc">}</span><span class="ss">/checkpoint_epoch_</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:03d}</span><span class="ss">.pt"</span></span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a>        torch.save(checkpoint, ckpt_path)</span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Saved checkpoint: </span><span class="sc">{</span>ckpt_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training completed!"</span>)</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a><span class="co"># 최종 Loss 그래프</span></span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_history, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Average Loss'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training Loss Over Time'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="ss">f"</span><span class="sc">{</span>OUT_DIR<span class="sc">}</span><span class="ss">/loss_curve.png"</span>, dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Saved loss curve: </span><span class="sc">{</span>OUT_DIR<span class="sc">}</span><span class="ss">/loss_curve.png"</span>)</span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a><span class="co"># 최종 샘플 생성</span></span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Generating final samples..."</span>)</span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a>        torch.cuda.manual_seed_all(<span class="dv">42</span>)</span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> model.sample(image_size<span class="op">=</span>IMG_SIZE, batch_size<span class="op">=</span><span class="dv">25</span>, channels<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> make_grid(samples.cpu(), nrow<span class="op">=</span><span class="dv">10</span>, padding<span class="op">=</span><span class="dv">2</span>, pad_value<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> grid.clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a>    save_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>OUT_DIR<span class="sc">}</span><span class="ss">/final_samples.png"</span></span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a>    save_image(grid, save_path)</span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a>    plt.imshow(grid.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).numpy())</span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb19-119"><a href="#cb19-119" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb19-120"><a href="#cb19-120" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb19-121"><a href="#cb19-121" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Saved final samples: </span><span class="sc">{</span>save_path<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Starting training for 25 epochs...
Device: cuda
Total batches per epoch: 127
[Epoch   1/25] avg_loss = 0.171135</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_001.png
[Epoch   2/25] avg_loss = 0.069920</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_002.png
[Epoch   3/25] avg_loss = 0.055337</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_003.png
[Epoch   4/25] avg_loss = 0.049606</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_004.png
[Epoch   5/25] avg_loss = 0.046708</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_005.png
[Epoch   6/25] avg_loss = 0.044768</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-12.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_006.png
[Epoch   7/25] avg_loss = 0.043179</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-14.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_007.png
[Epoch   8/25] avg_loss = 0.041937</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-18-output-16.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved image: ./output/generated_img_008.png</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-3804794597.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">     30</span>     num_batches <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">0</span>
<span class="ansi-green-fg ansi-bold">     31</span> 
<span class="ansi-green-fg">---&gt; 32</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">for</span> images<span class="ansi-blue-fg">,</span> _ <span class="ansi-green-fg">in</span> dataloader<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     33</span>         images <span class="ansi-blue-fg">=</span> images<span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     34</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-fg ansi-bold">    730</span>                 <span class="ansi-red-fg"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>
<span class="ansi-green-fg ansi-bold">    731</span>                 self<span class="ansi-blue-fg">.</span>_reset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># type: ignore[call-arg]</span>
<span class="ansi-green-fg">--&gt; 732</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    733</span>             self<span class="ansi-blue-fg">.</span>_num_yielded <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-fg ansi-bold">    734</span>             if (

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-fg ansi-bold">    786</span>     <span class="ansi-green-fg">def</span> _next_data<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    787</span>         index <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_index<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># may raise StopIteration</span>
<span class="ansi-green-fg">--&gt; 788</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_dataset_fetcher<span class="ansi-blue-fg">.</span>fetch<span class="ansi-blue-fg">(</span>index<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># may raise StopIteration</span>
<span class="ansi-green-fg ansi-bold">    789</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_pin_memory<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    790</span>             data <span class="ansi-blue-fg">=</span> _utils<span class="ansi-blue-fg">.</span>pin_memory<span class="ansi-blue-fg">.</span>pin_memory<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>_pin_memory_device<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py</span> in <span class="ansi-cyan-fg">fetch</span><span class="ansi-blue-fg">(self, possibly_batched_index)</span>
<span class="ansi-green-fg ansi-bold">     50</span>                 data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">.</span>__getitems__<span class="ansi-blue-fg">(</span>possibly_batched_index<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     51</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">                 </span>data <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> possibly_batched_index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg ansi-bold">     53</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     54</span>             data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>possibly_batched_index<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, idx)</span>
<span class="ansi-green-fg ansi-bold">    344</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    345</span>             sample_idx <span class="ansi-blue-fg">=</span> idx <span class="ansi-blue-fg">-</span> self<span class="ansi-blue-fg">.</span>cumulative_sizes<span class="ansi-blue-fg">[</span>dataset_idx <span class="ansi-blue-fg">-</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">--&gt; 346</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>datasets<span class="ansi-blue-fg">[</span>dataset_idx<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">[</span>sample_idx<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg ansi-bold">    347</span> 
<span class="ansi-green-fg ansi-bold">    348</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torchvision/datasets/flowers102.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, idx)</span>
<span class="ansi-green-fg ansi-bold">     88</span> 
<span class="ansi-green-fg ansi-bold">     89</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>transform<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 90</span><span class="ansi-red-fg">             </span>image <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>transform<span class="ansi-blue-fg">(</span>image<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     91</span> 
<span class="ansi-green-fg ansi-bold">     92</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>target_transform<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, img)</span>
<span class="ansi-green-fg ansi-bold">     93</span>     <span class="ansi-green-fg">def</span> __call__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> img<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     94</span>         <span class="ansi-green-fg">for</span> t <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>transforms<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 95</span><span class="ansi-red-fg">             </span>img <span class="ansi-blue-fg">=</span> t<span class="ansi-blue-fg">(</span>img<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     96</span>         <span class="ansi-green-fg">return</span> img
<span class="ansi-green-fg ansi-bold">     97</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1773</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_compiled_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># type: ignore[misc]</span>
<span class="ansi-green-fg ansi-bold">   1774</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1775</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">   1776</span> 
<span class="ansi-green-fg ansi-bold">   1777</span>     <span class="ansi-red-fg"># torchrec tests the code consistency with the following code</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1784</span>                 <span class="ansi-green-fg">or</span> _global_backward_pre_hooks <span class="ansi-green-fg">or</span> _global_backward_hooks
<span class="ansi-green-fg ansi-bold">   1785</span>                 or _global_forward_hooks or _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1786</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> forward_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">   1787</span> 
<span class="ansi-green-fg ansi-bold">   1788</span>         result <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, img)</span>
<span class="ansi-green-fg ansi-bold">    352</span>             PIL Image <span class="ansi-green-fg">or</span> Tensor<span class="ansi-blue-fg">:</span> Rescaled image<span class="ansi-blue-fg">.</span>
<span class="ansi-green-fg ansi-bold">    353</span>         """
<span class="ansi-green-fg">--&gt; 354</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> F<span class="ansi-blue-fg">.</span>resize<span class="ansi-blue-fg">(</span>img<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>interpolation<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>max_size<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>antialias<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    355</span> 
<span class="ansi-green-fg ansi-bold">    356</span>     <span class="ansi-green-fg">def</span> __repr__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> str<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py</span> in <span class="ansi-cyan-fg">resize</span><span class="ansi-blue-fg">(img, size, interpolation, max_size, antialias)</span>
<span class="ansi-green-fg ansi-bold">    475</span>             warnings<span class="ansi-blue-fg">.</span>warn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored."</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    476</span>         pil_interpolation <span class="ansi-blue-fg">=</span> pil_modes_mapping<span class="ansi-blue-fg">[</span>interpolation<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">--&gt; 477</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> F_pil<span class="ansi-blue-fg">.</span>resize<span class="ansi-blue-fg">(</span>img<span class="ansi-blue-fg">,</span> size<span class="ansi-blue-fg">=</span>output_size<span class="ansi-blue-fg">,</span> interpolation<span class="ansi-blue-fg">=</span>pil_interpolation<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    478</span> 
<span class="ansi-green-fg ansi-bold">    479</span>     <span class="ansi-green-fg">return</span> F_t<span class="ansi-blue-fg">.</span>resize<span class="ansi-blue-fg">(</span>img<span class="ansi-blue-fg">,</span> size<span class="ansi-blue-fg">=</span>output_size<span class="ansi-blue-fg">,</span> interpolation<span class="ansi-blue-fg">=</span>interpolation<span class="ansi-blue-fg">.</span>value<span class="ansi-blue-fg">,</span> antialias<span class="ansi-blue-fg">=</span>antialias<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torchvision/transforms/_functional_pil.py</span> in <span class="ansi-cyan-fg">resize</span><span class="ansi-blue-fg">(img, size, interpolation)</span>
<span class="ansi-green-fg ansi-bold">    251</span>         <span class="ansi-green-fg">raise</span> TypeError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f"Got inappropriate size arg: {size}"</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    252</span> 
<span class="ansi-green-fg">--&gt; 253</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> img<span class="ansi-blue-fg">.</span>resize<span class="ansi-blue-fg">(</span>tuple<span class="ansi-blue-fg">(</span>size<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> interpolation<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    254</span> 
<span class="ansi-green-fg ansi-bold">    255</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/PIL/Image.py</span> in <span class="ansi-cyan-fg">resize</span><span class="ansi-blue-fg">(self, size, resample, box, reducing_gap)</span>
<span class="ansi-green-fg ansi-bold">   2319</span>                 )
<span class="ansi-green-fg ansi-bold">   2320</span> 
<span class="ansi-green-fg">-&gt; 2321</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_new<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>im<span class="ansi-blue-fg">.</span>resize<span class="ansi-blue-fg">(</span>size<span class="ansi-blue-fg">,</span> resample<span class="ansi-blue-fg">,</span> box<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">   2322</span> 
<span class="ansi-green-fg ansi-bold">   2323</span>     def reduce(

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/FLUOLANET\.github\.io\/Oxford_102_Flower_Tiny_DDPM\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>